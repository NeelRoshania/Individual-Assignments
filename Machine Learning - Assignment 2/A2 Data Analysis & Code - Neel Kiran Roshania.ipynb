{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "# A2: Written Assessment (Individual) - Classification Modeling Case Study\n",
    "\n",
    "\n",
    "\n",
    "Machine Learning DAT 5303\n",
    "\n",
    "Attn: Prof. Chase Kusterer & Ayelet\n",
    "\n",
    "15 March 2020\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "1. 5 Ways to increase cross-sell success, HBR 2020, https://hbr.org/2016/11/5-ways-to-increase-your-cross-selling\n",
    "\n",
    "2. 25 Of The Best California Red Wines under $25, https://www.pastemagazine.com/drink/red-wine/25-of-the-best-california-red-wines-under-25/#adelaida-grenache-20-\n",
    "\n",
    "3. California Top Wines for $15 or less, https://www.foodandwine.com/wine-regions/california/california-top-wines-for-15-dollars-and-less\n",
    "\n",
    "4. Food and Wine Pairing Basics, https://winefolly.com/wine-pairing/getting-started-with-food-and-wine-pairing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "As part of <em>Apprentice Chef's</em> product offering, <em>Halfway There</em> (HWT) is another subscription service available to new and existing customers. Existing customers are either inactive, basic or premium subscribers of the Weekly Meal Plan (WP) subscription. \n",
    "\n",
    "The aim of this project is to,\n",
    "1. Produce a model that can accurately predict whether either customer will subscribe to HWT as part of their cross-selling strategy.\n",
    "2. Produce two insights and one key recommendation for key business stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stakeholder Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the following sections for business and technical information,\n",
    "1. Section 4 and 5 for key business stakeholders.\n",
    "2. Section 2 and 3 for key Data Science stakeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion of unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"data/df_feature_engineering.csv\")\n",
    "df_optimization = df_original.copy()\n",
    "df_optimization = df_optimization.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# feature name correction\n",
    "df_optimization.rename(columns={'MOBILE_NUMBER': 'MOBILE_REGISTRATION'}, inplace=True)\n",
    "\n",
    "# preparing response variable data\n",
    "predictor = 'HWT_SUBSCRIBER'\n",
    "target = df_optimization.loc[:, predictor]\n",
    "all_features = df_optimization.loc[:, df_optimization.columns.isin([predictor]) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResults():\n",
    "    \n",
    "    # Class to append results of modeling scenarios into a convenient wrapper\n",
    "    #    - Assumes pandas as a preloaded resource\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.df = pd.DataFrame(columns = self.columns)\n",
    "    \n",
    "    # save results into class\n",
    "    def save(self, model_dict_outcome):\n",
    "        self.df = pd.concat([self.df, pd.DataFrame(model_dict_outcome)])\n",
    "    \n",
    "    # display results\n",
    "    def display(self):\n",
    "        return self.df\n",
    "    \n",
    "    # export results\n",
    "    def export_csv(self, location):\n",
    "        self.location = location\n",
    "        self.df.to_csv(self.location)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalityTest():\n",
    "     \n",
    "    # Determine whether the supplied function could be sampled from a Gaussian distribution\n",
    "    #   - Normality tests have been validated by 100 randomly distributed normal floats\n",
    "    #   - pandas is a pre-assumed dependency\n",
    "    #      - NormalityTest(np.random.randn(100), 0.05, 0).get_result()\n",
    "    #   - Source: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n",
    "    \n",
    "    from scipy import stats\n",
    "    from numpy.random import seed, randn, seed\n",
    " \n",
    "    def __init__(self, arr, alpha, dataframe, predictor_str):\n",
    "        self.arr = arr\n",
    "        self.alpha = alpha\n",
    "        self.dataframe = dataframe\n",
    "        self.predictor_str = predictor_str\n",
    "        return None\n",
    "    \n",
    "    def check_normal_dist(self):\n",
    "        return {\n",
    "            'is_normally_distributed': {\n",
    "                'shapiroWilk': self.shapiroWilk(self.alpha),\n",
    "                'd_agostinoK2': self.d_agostinoK2(self.alpha),\n",
    "                'anderson_darling': self.anderson_darling(self.alpha)},\n",
    "        }\n",
    "        \n",
    "    def shapiroWilk(self, alpha):\n",
    "        stat, p = self.stats.shapiro(self.arr)\n",
    "        if p > alpha:\n",
    "            return 'Gaussian (fail to reject H0)'\n",
    "        else:\n",
    "            return 'Not Gaussian (reject H0)'\n",
    "    \n",
    "    def d_agostinoK2(self, alpha):\n",
    "        stat, p = self.stats.normaltest(self.arr)\n",
    "        if p > alpha:\n",
    "            return 'Gaussian (fail to reject H0)'\n",
    "        else:\n",
    "            return 'Not Gaussian (reject H0)'\n",
    "        \n",
    "    def anderson_darling(self, alpha):\n",
    "        \n",
    "        outcome = {\n",
    "            \"statistic\": None,\n",
    "            \"percentile\": [],\n",
    "            \"sl_cv\": [],\n",
    "            \"result\": []\n",
    "        }\n",
    "        # normality test\n",
    "        result = self.stats.anderson(self.arr)\n",
    "        statistic = result.statistic\n",
    "        p = 0\n",
    "\n",
    "        for i in range(len(result.critical_values)):\n",
    "            sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "            if result.statistic < result.critical_values[i]:\n",
    "                outcome['sl_cv'].append([sl, cv])\n",
    "                outcome['result'].append([\"Normal (Fail to reject H0)\"])\n",
    "            else:\n",
    "                outcome['sl_cv'].append([sl, cv])\n",
    "                outcome['result'].append([\"Not Normal (Reject H0)\"])\n",
    "                \n",
    "        outcome['statistic'] = statistic\n",
    "        return outcome\n",
    "    \n",
    "    def check_population_mean(self, pop_mean):\n",
    "        \n",
    "        # NH: population mean is zero\n",
    "        \n",
    "        outcome = {}\n",
    "        data = self.arr\n",
    "        tset, pval = self.stats.ttest_1samp(data, pop_mean) # t-test\n",
    "        if pval < 0.05:    # alpha value is 0.05 or 5%\n",
    "            outcome['status'] = \"Reject Null hypothesis\"\n",
    "        else:\n",
    "            outcome['status'] = \"Accept Null hypothesis\"\n",
    "        outcome['sample_mean'] = np.mean(data)\n",
    "        return outcome\n",
    "    \n",
    "    def get_correlation_matrix(self):\n",
    "        \n",
    "        # arr and dataframe will be joined to produce correlation matrix\n",
    "        return self.dataframe.join(pd.DataFrame({'arr': self.arr})).corr()\n",
    "    \n",
    "    \n",
    "    def check_homoscedasticity(self, model):\n",
    "        \n",
    "        # generate a qqplot to visually inspect quantiles that break normality\n",
    "        \n",
    "        # We can also use two statistical tests: Breusch-Pagan and Goldfeld-Quandt. In both of them, the null hypothesis assumes homoscedasticity.\n",
    "        #    - A p-value below a certain level (like 0.05) indicates we should reject the null in favor of heteroscedasticity.\n",
    "        #    - Source: https://towardsdatascience.com/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0\n",
    " \n",
    "        import pylab \n",
    "        import scipy.stats as stats\n",
    "\n",
    "        measurements = model.resid  \n",
    "        stats.probplot(measurements, dist=\"norm\", plot=pylab)\n",
    "        pylab.show()\n",
    "    \n",
    "    \n",
    "    def get_vif(self):\n",
    "        # Variance inflation factor to measure collinearity among features\n",
    "\n",
    "        feature_name = []\n",
    "        vif_value = []\n",
    "        rsq_value = []\n",
    "        self.df_vif = self.dataframe.copy()\n",
    "        if self.predictor_str in self.df_vif.columns:\n",
    "            self.df_vif = self.df_vif.drop([self.predictor_str], axis=1)\n",
    "        \n",
    "        for i in range(0, len(self.df_vif.columns)):\n",
    "            # prepare features\n",
    "            X = self.df_vif.loc[:, self.df_vif.columns != self.df_vif.columns[i]]\n",
    "            y = self.df_vif.loc[:, self.df_vif.columns == self.df_vif.columns[i]]\n",
    "\n",
    "            # Regress feature on every other feature\n",
    "            lr = LinearRegression().fit(X, y)\n",
    "\n",
    "            # Determine rsq\n",
    "            rsq = lr.score(X, y)\n",
    "            if rsq != 1:\n",
    "                vif = round(1 / (1 - rsq), 2)\n",
    "            else:\n",
    "                vif = float(\"inf\")\n",
    "\n",
    "            feature_name.append(self.df_vif.columns[i])\n",
    "            rsq_value.append(rsq)\n",
    "            vif_value.append(vif)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "                \"r_squared\": rsq_value,\n",
    "                \"vif\": vif_value },\n",
    "            index = feature_name\n",
    "        ).sort_values(by=\"vif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def skl_train_test_pred_results(model, fit_X, fit_y, test_X, test_y, pred_X):\n",
    "#     quick method to output model, train and test scores\n",
    "    \n",
    "    # Fit and score\n",
    "    mod_fit = model.fit(fit_X, fit_y)\n",
    "    mod_train_score = model.score(fit_X, fit_y)\n",
    "    mod_test_score = model.score(test_X, test_y)\n",
    "    y_pred = mod_fit.predict(pred_X)\n",
    "    \n",
    "    return mod_fit, mod_train_score, mod_test_score, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def skl_mod_confusion_matrix_roc_auc(y_true, y_pred, y_score):\n",
    "    # Thus in binary classification, \n",
    "#         - C00, True  Negatives \n",
    "#         - C01, False Positive\n",
    "#         - C10, False Negative  \n",
    "#         - C11  True  Positive\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_score = {\n",
    "        'TN': cm[0, 0],\n",
    "        'FP': cm[0, 1],\n",
    "        'FN': cm[1, 0],\n",
    "        'TP': cm[1, 1]\n",
    "    }\n",
    "    \n",
    "    return cm_score, roc_auc_score(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Variance inflation factor to measure collinearity among features\n",
    "def vim_multicollinearity(df):\n",
    "    feature_name = []\n",
    "    vif_value = []\n",
    "    rsq_value = []\n",
    "\n",
    "    for i in range(0, len(df.columns)):\n",
    "        # prepare features\n",
    "        X = df.loc[:, df.columns != df.columns[i]]\n",
    "        y = df.loc[:, df.columns == df.columns[i]]\n",
    "\n",
    "        # Regress feature on every other feature\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        \n",
    "        # Determine rsq\n",
    "        rsq = lr.score(X, y)\n",
    "        if rsq != 1:\n",
    "            vif = round(1 / (1 - rsq), 2)\n",
    "        else:\n",
    "            vif = float(\"inf\")\n",
    "\n",
    "        feature_name.append(df.columns[i])\n",
    "        rsq_value.append(rsq)\n",
    "        vif_value.append(vif)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "            \"r_squared\": rsq_value,\n",
    "            \"vif\": vif_value },\n",
    "        index = feature_name\n",
    "    ).sort_values(by=\"vif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def statsmodel_ols_lgst(library, model_type, X_train, X_test, y_train, y_test, class_likelihood):\n",
    "    # Method to automate process of retrieving performance parameters\n",
    "    \n",
    "    model_spec = {\n",
    "        'ols': sm.OLS(y_train, X_train).fit(),\n",
    "        'lgst': sm.Logit(y_train, X_train).fit(method='ncg')\n",
    "    }\n",
    "    \n",
    "    model_spec_sklearn = {\n",
    "        'ols': LinearRegression().fit(X_train, y_train),\n",
    "        'lgst': LogisticRegression().fit(X_train, y_train)\n",
    "    }\n",
    "    \n",
    "    if library == 'statsmodels':\n",
    "        model = model_spec[model_type]\n",
    "\n",
    "        # apply class heuristic\n",
    "        #     - Any class less than 0.5: 0\n",
    "        #     - ANy class greater than 0.5: 1\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[y_pred < class_likelihood] = 0\n",
    "        y_pred[y_pred >= class_likelihood] = 1\n",
    "        y_pred = y_pred.astype(int)\n",
    "        \n",
    "        # Get significant features\n",
    "        mod_sig_features = list(model.pvalues[model.pvalues <= 0.05].index.values)\n",
    "        \n",
    "    elif library == 'sklearn':\n",
    "        model = model_spec_sklearn[model_type]\n",
    "        \n",
    "        # apply class heuristic\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[y_pred < class_likelihood] = 0\n",
    "        y_pred[y_pred >= class_likelihood] = 1\n",
    "        y_pred = y_pred.astype(int)\n",
    "        \n",
    "        # Get significant features\n",
    "        mod_sig_features = []\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"KindError: Library argument is incorrect.\")\n",
    "\n",
    "    # Get scores: output interpreted as probability of predicting class 1\n",
    "    mod_cm_score, mod_auc_score = skl_mod_confusion_matrix_roc_auc(y_test, y_pred, y_pred)\n",
    "    mod_precision = mod_cm_score['TP']/(mod_cm_score['TP']+mod_cm_score['FP'])\n",
    "    \n",
    "    return model, mod_cm_score, mod_auc_score, mod_precision, mod_sig_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier and threshold mapping  \n",
    "def threshold_outlier_flagging(dataframe, feature, threshold_val, threshold_type, bound):\n",
    "#     automate outlier and flagging process\n",
    "    if threshold_type == 'outlier':\n",
    "        if bound == 'high':\n",
    "            _out_label = \"out_{}_hi\".format(feature)\n",
    "            dataframe.loc[:, _out_label] = 0\n",
    "            for index, val in dataframe.iterrows(): \n",
    "                if dataframe.loc[index, feature] > threshold_val:\n",
    "                    dataframe.loc[index, _out_label] = 1\n",
    "        elif bound == \"low\":\n",
    "            _out_label = \"out_{}_lo\".format(feature)\n",
    "            dataframe.loc[:, _out_label] = 0\n",
    "            for index, val in dataframe.iterrows(): \n",
    "                if dataframe.loc[index, feature] < threshold_val:\n",
    "                    dataframe.loc[index, _out_label] = 1\n",
    "        else:\n",
    "            print(\"Outlier flagging failed\")\n",
    "            \n",
    "    elif threshold_type == 'threshold':\n",
    "        if bound == 'high':\n",
    "            _out_label = \"flag_{}_hi\".format(feature)\n",
    "            dataframe.loc[:, _out_label] = 0\n",
    "            for index, val in dataframe.iterrows(): \n",
    "                if dataframe.loc[index, feature] > threshold_val:\n",
    "                    dataframe.loc[index, _out_label] = 1\n",
    "        elif bound == \"low\":\n",
    "            _out_label = \"flag_{}_lo\".format(feature)\n",
    "            dataframe.loc[:, _out_label] = 0\n",
    "            for index, val in dataframe.iterrows(): \n",
    "                if dataframe.loc[index, feature] < threshold_val:\n",
    "                    dataframe.loc[index, _out_label] = 1\n",
    "        else:\n",
    "            print(\"Threshold flagging failed\")\n",
    "            \n",
    "    elif threshold_type == 'trend':\n",
    "        _out_label = \"trend_{}\".format(feature)\n",
    "        dataframe.loc[:, _out_label] = 0\n",
    "        for index, val in dataframe.iterrows(): \n",
    "            if dataframe.loc[index, feature] == threshold_val:\n",
    "                dataframe.loc[index, _out_label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a ncol x 4 row matrix of distributions\n",
    "def plot_box_facets(_df, df, fig_rc, viz_type, y, cat_x):\n",
    "    g_count = 0\n",
    "    \n",
    "    if viz_type == 'box':\n",
    "        if y not in cat_x:\n",
    "            a = plt.subplot(fig_rc[0], fig_rc[1], g_count+1)\n",
    "\n",
    "            # plot a facet\n",
    "            box_plot = sns.boxplot(x=cat_x, y=y, data=df)\n",
    "            g_count += 1\n",
    "            \n",
    "            # despine figure\n",
    "            sns.despine()\n",
    "            return box_plot\n",
    "    else:\n",
    "        raise Exception(\"Failed to generated Box Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Redundant features\n",
    "    - Known collinear binary features\n",
    "    - FIRST_NAME, FAMILY_NAME, EMAIL, NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optimization.drop(\n",
    "            [\"flag_WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT_lo\",\n",
    "            \"NAME\",\n",
    "            \"EMAIL\",\n",
    "            \"FIRST_NAME\",\n",
    "            \"FAMILY_NAME\"], \n",
    "            axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly Meal Plan subscriber type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HWT_SUBSCRIBER</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe_WP_INACTIVE_SUB</th>\n",
       "      <th>fe_WP_BASIC_SUB</th>\n",
       "      <th>fe_WP_PREMIUM_SUB</th>\n",
       "      <th>fe_WP_NOT_SUB</th>\n",
       "      <th>MOBILE_REGISTRATION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>57376.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>376476.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>87228.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "      <td>604244.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>229446.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>519</td>\n",
       "      <td>1729334.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>104813.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291</td>\n",
       "      <td>911871.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        HWT_SUBSCRIBER  \\\n",
       "fe_WP_INACTIVE_SUB fe_WP_BASIC_SUB fe_WP_PREMIUM_SUB fe_WP_NOT_SUB MOBILE_REGISTRATION                   \n",
       "0                  0               1                 0             0                                20   \n",
       "                                                                   1                               132   \n",
       "                   1               0                 0             0                                32   \n",
       "                                                                   1                               248   \n",
       "1                  0               0                 0             0                                45   \n",
       "                                                                   1                               519   \n",
       "                                                     1             0                                34   \n",
       "                                                                   1                               291   \n",
       "\n",
       "                                                                                            REVENUE  \n",
       "fe_WP_INACTIVE_SUB fe_WP_BASIC_SUB fe_WP_PREMIUM_SUB fe_WP_NOT_SUB MOBILE_REGISTRATION               \n",
       "0                  0               1                 0             0                      57376.750  \n",
       "                                                                   1                     376476.875  \n",
       "                   1               0                 0             0                      87228.500  \n",
       "                                                                   1                     604244.125  \n",
       "1                  0               0                 0             0                     229446.000  \n",
       "                                                                   1                    1729334.500  \n",
       "                                                     1             0                     104813.000  \n",
       "                                                                   1                     911871.750  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of total meals ordered and weeks subscribed to weekly plan are not all perfectly divisible by 3 or 5\n",
    "#     - Assumption: Weekly plan subscription is a stratified discount plan as opposed to a weekly delivery plan\n",
    "# If the total number of meals order is greater \n",
    "#     - Than a multiple of 3 weeks subscribed to the weekly plan -> Basic subscriber\n",
    "#     - Than a multiple of 5 5 of weeks subscribed to the weekly -> Premium subscriber\n",
    "#     - Otherwise inactive weekly\n",
    "\n",
    "# instantiate features\n",
    "df_optimization[\"fe_WP_NOT_SUB\"] = 0\n",
    "df_optimization[\"fe_WP_INACTIVE_SUB\"] = 0 \n",
    "df_optimization[\"fe_WP_BASIC_SUB\"] = 0 \n",
    "df_optimization[\"fe_WP_PREMIUM_SUB\"] = 0\n",
    "\n",
    "# Generate features\n",
    "for index, val in df_optimization.iterrows(): \n",
    "    \n",
    "    # stratify by type of weekly plan subscriber\n",
    "    if df_optimization.loc[index, \"WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT\"]*3 > df_optimization.loc[index, \"TOTAL_MEALS_ORDERED\"]:\n",
    "        df_optimization.loc[index, \"fe_WP_BASIC_SUB\"] = 1\n",
    "    elif df_optimization.loc[index, \"WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT\"]*5 > df_optimization.loc[index, \"TOTAL_MEALS_ORDERED\"]:\n",
    "        df_optimization.loc[index, \"fe_WP_PREMIUM_SUB\"] = 1\n",
    "    else:\n",
    "        df_optimization.loc[index, \"fe_WP_INACTIVE_SUB\"] = 1\n",
    "    \n",
    "#     # feature out customers that are not subscribers of a weekly meal plan\n",
    "    if df_optimization.loc[index, \"WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT\"] == 0:\n",
    "        df_optimization.loc[index, \"fe_WP_NOT_SUB\"] = 1\n",
    "\n",
    "# aggregate by HWT_SUBSCRIBER and share of revenue\n",
    "df_optimization.loc[:, [\"fe_WP_BASIC_SUB\", \"fe_WP_PREMIUM_SUB\", \"fe_WP_INACTIVE_SUB\", \"fe_WP_NOT_SUB\", \"MOBILE_REGISTRATION\", \"HWT_SUBSCRIBER\", \"REVENUE\"]].\\\n",
    "groupby([\"fe_WP_INACTIVE_SUB\", \"fe_WP_BASIC_SUB\", \"fe_WP_PREMIUM_SUB\", \"fe_WP_NOT_SUB\", \"MOBILE_REGISTRATION\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual subscription customers preferred to register for HWT through their mobile phones.\n",
    "- 519 Inactive WP subscribers were also HWT subscribers and registered with their mobile phones. These customers are not entitled to a weekly plan discount and so there must some other motivating factor.\n",
    "- 325 customers were unique HWT subscribers and also registered for the service with the mobile phones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pool of customers seem hold evidence to suggest that Apprentice's cross-selling strategy is diversifying their revenue streams. And since they have never interfaced Apprentice Chef before, these must be the new customers and the others existing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize feature\n",
    "df_optimization.rename(columns={\"fe_WP_NOT_SUB\": \"fe_ONLY_HWT_CUSTOMER\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOBILE_LOGINS_CNT</th>\n",
       "      <th>PC_LOGINS_CNT</th>\n",
       "      <th>HWT_SUBSCRIBER</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe_ONLY_HWT_CUSTOMER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2180</td>\n",
       "      <td>8139</td>\n",
       "      <td>1478</td>\n",
       "      <td>3084106.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693</td>\n",
       "      <td>2595</td>\n",
       "      <td>468</td>\n",
       "      <td>1016684.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MOBILE_LOGINS_CNT  PC_LOGINS_CNT  HWT_SUBSCRIBER  \\\n",
       "fe_ONLY_HWT_CUSTOMER                                                     \n",
       "0                                  2180           8139            1478   \n",
       "1                                   693           2595             468   \n",
       "\n",
       "                         REVENUE  \n",
       "fe_ONLY_HWT_CUSTOMER              \n",
       "0                     3084106.75  \n",
       "1                     1016684.75  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimization\\\n",
    "    .loc[:, df_optimization.columns\\\n",
    "    .isin([\"fe_ONLY_HWT_CUSTOMER\", \"HWT_SUBSCRIBER\", \"MOBILE_LOGINS_CNT\", \"PC_LOGINS_CNT\", \"REVENUE\"]) == True]\\\n",
    "    .groupby(\"fe_ONLY_HWT_CUSTOMER\")\\\n",
    "    .agg({\"MOBILE_LOGINS_CNT\": 'sum', \"PC_LOGINS_CNT\": 'sum', \"HWT_SUBSCRIBER\": 'count', \"REVENUE\": 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a revenue standpoint, unique HWT customers generated nearly 1/3 of the observed revenue. And even though they prefered to login with their mobile phones, a fair amount of platform engagement occurs on desktop computers.\n",
    "\n",
    "#### What makes these new customers different?\n",
    "These new customers receive a half bottle of wine from a local California vineyard every Wednesday.\n",
    "\n",
    "A typical product that comes from this region, Paso Robles, is Adelaida Grenache (+1$20). It is branded as an affordable yet alluring selection of red wine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.pastemagazine.com/www/articles/Best-reds-CA-1-Adelaida.jpg\" style=\"width:20em\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"Grenache is a widely planted grape that probably originated in Spain. It likes hot, dry conditions (welcome to Paso\n",
    "    Robles!) and produces wines with low tannins and a lot of red berry and spice notes-leathery or tarry notes enter the\n",
    "    picture with age.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most affordable wine available from that region is a 2006 Camelot Cabernet Sauvignon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://attardcowines.com/wp-content/uploads/2019/08/78e14edcbf28b3720b6d23db94984107_camelot-rosso-1-5lt.jpg\" style=\"width: 20em\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red wines are usually more bitter than white wines the white or sweet whine. From a food pairing perspective, what they make up for in bitterness, sweetness or acidity, they lack in fatiness, spicyness and saltiness. Ideal food compliments for each type of wine are,\n",
    "1. White - Macaroni for a classy Monday dinner\n",
    "2. Red - Machego cheese and crackers for an ideal mid week break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend, flag and outlier flagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have captured two types of customers so far,\n",
    "1. Existing that are dual subscribers of WP only or WP & HWT.\n",
    "2. New Customers that only purchased the HWT subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate customers based on type\n",
    "df_dual_WP_HWT = df_optimization[df_optimization[\"fe_ONLY_HWT_CUSTOMER\"] == 0]\n",
    "df_only_HWT = df_optimization[df_optimization[\"fe_ONLY_HWT_CUSTOMER\"] == 1]\n",
    "\n",
    "# copy dataframes\n",
    "df_flagged = df_optimization.copy()\n",
    "\n",
    "# export data for further analysis\n",
    "df_dual_WP_HWT.to_csv(\"existing_customers.csv\")\n",
    "df_dual_WP_HWT.to_csv(\"new_HWT_customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets identify outliers, trends outliers, high and low regions for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d292df9eb54a483aaf761fe473ed3fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Feature', options=('REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(Feature, Customer)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# box plot visualiztion\n",
    "def f(Feature, Customer):\n",
    "    \n",
    "    # get dataframe of choice\n",
    "    get_df = {\n",
    "        \"Existing\": df_dual_WP_HWT,\n",
    "        \"New\": df_only_HWT,\n",
    "        \"All\": df_optimization,\n",
    "    }\n",
    "    \n",
    "    # Plot feature\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    ax = plot_box_facets(\n",
    "        get_df[Customer].loc[:, Feature],\n",
    "        get_df[Customer],\n",
    "        viz_type = 'box',\n",
    "        fig_rc = [4, 4],\n",
    "        y = Feature,\n",
    "        cat_x = predictor\n",
    "    )\n",
    "    \n",
    "    print(\"Copy and paste for auto-flagging: {}\".format(Feature))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "# Provide feature selection drop down\n",
    "widgets.interact(f, Feature=df_dual_WP_HWT.columns[df_dual_WP_HWT.columns != predictor], Customer=[\"Existing\", \"New\", \"All\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoflagging all customers\n",
    "threshold_outlier_flagging(df_flagged, \"REVENUE\", 4200, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"TOTAL_MEALS_ORDERED\", 175, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"UNIQUE_MEALS_PURCH\", 12.5, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"CUSTOMER_SERVICE_TICKETS_CNT\", 12, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"MEALS_CANCEL_BEFORE_NOON\", 6, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT\", 33, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"ORDERS_DELIVERED_BEFORE_DELIVERY_CNT\", 7, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"ORDERS_DELIVERED_AFTER_DELIVERY_CNT\", 8, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"FRIDGE_LOCKER_IN_PACKAGE_ROOM\", 1, \"trend\", \"hight\")\n",
    "threshold_outlier_flagging(df_flagged, \"PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE\", 30, \"threshold\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"SECONDS_WATCHING_PREP_VID_AVG\", 280, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"LARGEST_ORDER_SIZE\", 8, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"MASTER_CLASSES_ATTENDED_CNT\", 2, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"MEAL_RATING_MEDIAN\", 4, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"SITE_CLICKS_PER_VISIT_AVG\", 8, \"outlier\", \"low\")\n",
    "threshold_outlier_flagging(df_flagged, \"PHOTOS_VIEWED_COUNT\", 400, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"fe_MEAL_CHOICE_SPECIFICITY\", 0.28, \"outlier\", \"high\")\n",
    "threshold_outlier_flagging(df_flagged, \"fe_SITE_CLICK_RATE\", 0.4, \"outlier\", \"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization strategy\n",
    "- Remove redundant features\n",
    "    - Test improvement\n",
    "        - Criteria: count of p-values\n",
    "- Scale all count, continuous and discrete\n",
    "    - Test improvement\n",
    "        - Criteria: count of p-values\n",
    "- Transform all count, continuous and discrete\n",
    "    - Test improvement\n",
    "        - Criteria: count of p-values\n",
    "- Scale count, discrete and transform continuous\n",
    "    - Test improvement\n",
    "        - Criteria: count of p-values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define features sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\n",
    "    'REVENUE', \n",
    "    'SITE_VISIT_TIME_PER_VISIT_AVG', \n",
    "    'PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE', \n",
    "    'SECONDS_WATCHING_PREP_VID_AVG'\n",
    "                    ]\n",
    "\n",
    "# # MOBILE_LOGINS_CNT dropped, collinearity\n",
    "count_features = [\n",
    "    'TOTAL_MEALS_ORDERED', \n",
    "    'UNIQUE_MEALS_PURCH', \n",
    "    'CUSTOMER_SERVICE_TICKETS_CNT',\n",
    "    'PRODUCT_CATEGORIES_VIEWED', \n",
    "    'MEALS_CANCEL_BEFORE_NOON', \n",
    "    'MEALS_CANCEL_AFTER_NOON',\n",
    "    \"PC_LOGINS_CNT\", \n",
    "    \"WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT\",\n",
    "    \"ORDERS_DELIVERED_BEFORE_DELIVERY_CNT\", \n",
    "    \"ORDERS_DELIVERED_AFTER_DELIVERY_CNT\",\n",
    "    \"MASTER_CLASSES_ATTENDED_CNT\", \n",
    "    'SITE_CLICKS_PER_VISIT_AVG', \n",
    "    'PHOTOS_VIEWED_COUNT'\n",
    "                    ]\n",
    "\n",
    "\n",
    "boolean_features = [\n",
    "    'CROSS_SELL_SUCCESS', \n",
    "    'SPECIFIED_TASTE_AND_PREFERENCES',\n",
    "    'PACKAGE_ROOM_AT_CUSTOMER', \n",
    "    'FRIDGE_LOCKER_IN_PACKAGE_ROOM', \n",
    "                   ]\n",
    "\n",
    "discrete_features = [\n",
    "    'MOBILE_REGISTRATION', \n",
    "    'LARGEST_ORDER_SIZE', \n",
    "    'MEAL_RATING_MEDIAN'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary transformations of object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields to convert\n",
    "to_convert = [\"fe_CUSTOMER_COMPANY\", \"fe_CUSTOMER_DOMAIN\"]\n",
    "\n",
    "# make transformations\n",
    "binary_trans = pd.get_dummies(df_flagged.loc[:, to_convert], drop_first=True)\n",
    "\n",
    "# drop converted fields\n",
    "df_flagged.drop(to_convert, axis=1, inplace=True)\n",
    "df_flagged = df_flagged.join(binary_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup premodeling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model comparison statistics\n",
    "model_type = []\n",
    "count_sig_features = []\n",
    "sig_features = []\n",
    "auc_score = []\n",
    "sensitivity = []\n",
    "notes = []\n",
    "\n",
    "# feature set definition dictionary\n",
    "sig_feature_sets = {}\n",
    "\n",
    "# setup ModelResults class\n",
    "modeling_results = ModelResults([\"Model\", \"Transformation Method\", \"AUC\", \"AIC\", \"R2\", \"Precision\", \"Sig. features\", \"Notes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_flagged.loc[:, predictor]\n",
    "all_features = df_flagged.loc[:, df_flagged.columns != predictor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            all_features,\n",
    "            target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.638760\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lr_model, lr_mod_cm_score, lr_mod_auc_score, mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'ols', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": \"LinReg\",\n",
    "    \"Transformation Method\": [\"None\"],\n",
    "    \"AUC\": [lr_mod_auc_score],\n",
    "    \"AIC\": [lr_model.aic],\n",
    "    \"R2\": [lr_model.rsquared],\n",
    "    \"Precision\": [mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge on unscaled/transformed variables\"]\n",
    "})\n",
    "\n",
    "# define feature set\n",
    "sig_feature_sets[\"unscaled_lr\"] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.638760\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lgst_model, lgst_mod_cm_score, lgst_mod_auc_score, mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'lgst', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": [\"Lgst\"],\n",
    "    \"Transformation Method\": [\"Scale all\"],\n",
    "    \"AUC\": [lgst_mod_auc_score],\n",
    "    \"AIC\": [lgst_model.aic],\n",
    "    \"R2\": [lgst_model.prsquared],\n",
    "    \"Precision\": [mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge on scaled continuous and count features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets[\"unscaled_lgst\"] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale all count, continuous and discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_count_cont_disc = df_flagged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare dataframe for scaling\n",
    "df_to_scale = all_features\\\n",
    "    .loc[:, continuous_features + count_features + discrete_features]\n",
    "\n",
    "# scale all features\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(df_to_scale)\n",
    "df_to_scale = pd.DataFrame(scaler.transform(df_to_scale), columns=df_to_scale.columns)\n",
    "\n",
    "# merge scaled df with other fields\n",
    "df_scaled_count_cont_disc.loc[:, df_to_scale.columns] = df_to_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_scaled_count_cont_disc.loc[:, df_scaled_count_cont_disc.columns.isin([predictor]) == False],\n",
    "            df_scaled_count_cont_disc.loc[:, predictor],\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.321544\n",
      "         Iterations: 21\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 46\n",
      "         Hessian evaluations: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lr_model, lr_mod_cm_score, lr_mod_auc_score, mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'ols', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": [\"LinReg\"],\n",
    "    \"Transformation Method\": [\"Scale all\"],\n",
    "    \"AUC\": [lr_mod_auc_score],\n",
    "    \"AIC\": [lr_model.aic],\n",
    "    \"R2\": [lr_model.rsquared],\n",
    "    \"Precision\": [mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge scaled continuous and count features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets[\"scaled_all_lr\"] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.321544\n",
      "         Iterations: 21\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 46\n",
      "         Hessian evaluations: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lgst_model, lgst_mod_cm_score, lgst_mod_auc_score, mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'lgst', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": [\"Logit\"],\n",
    "    \"Transformation Method\": [\"Scale all\"],\n",
    "    \"AUC\": [lgst_mod_auc_score],\n",
    "    \"AIC\": [lgst_model.aic],\n",
    "    \"R2\": [lgst_model.prsquared],\n",
    "    \"Precision\": [mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge scaled continuous and count features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets[\"scaled_all_lgst\"] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform continuous and scale count, discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_cont_scaled_count_disc = df_flagged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Tranform continuous by square\n",
    "for i in df_transformed_cont_scaled_count_disc.loc[:, continuous_features]:\n",
    "    df_transformed_cont_scaled_count_disc.loc[:, i] = np.log(df_transformed_cont_scaled_count_disc.loc[:, i]).replace({-float('inf'): 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected warning as log calculation is being applied on dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for scaling\n",
    "df_to_scale = all_features\\\n",
    "    .loc[:, count_features + discrete_features]\n",
    "\n",
    "# Scale count and discrete\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(df_to_scale)\n",
    "df_to_scale = pd.DataFrame(scaler.transform(df_to_scale), columns=df_to_scale.columns)\n",
    "\n",
    "# merge scaled df with other fields\n",
    "df_transformed_cont_scaled_count_disc.loc[:, df_to_scale.columns] = df_to_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_transformed_cont_scaled_count_disc.loc[:, df_transformed_cont_scaled_count_disc.columns.isin([predictor]) == False],\n",
    "            df_transformed_cont_scaled_count_disc.loc[:, predictor],\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318692\n",
      "         Iterations: 33\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lr_model_trans_scaled, lr_mod_cm_score, lr_mod_auc_score, lr_mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'ols', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": [\"LinReg\"],\n",
    "    \"Transformation Method\": [\"Transform continuous, scale count and discrete\"],\n",
    "    \"AUC\": [lr_mod_auc_score],\n",
    "    \"AIC\": [lr_model_trans_scaled.aic],\n",
    "    \"R2\": [lr_model_trans_scaled.rsquared],\n",
    "    \"Precision\": [lr_mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge on transformed continuous, scaled count & discrete features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets[\"transformed_scaled_lr\"] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on statsmodels Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_transformed_cont_scaled_count_disc.loc[:, df_transformed_cont_scaled_count_disc.columns.isin([predictor]) == False],\n",
    "            df_transformed_cont_scaled_count_disc.loc[:, predictor],\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318692\n",
      "         Iterations: 33\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\nrosh\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lgst_model, lgst_mod_cm_score, lgst_mod_auc_score, mod_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'lgst', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save model results\n",
    "modeling_results.save({\n",
    "    \"Model\": [\"Logit\"],\n",
    "    \"Transformation Method\": [\"Transform continuous, scale count and discrete\"],\n",
    "    \"AUC\": [lgst_mod_auc_score],\n",
    "    \"AIC\": [lgst_model.aic],\n",
    "    \"R2\": [lgst_model.prsquared],\n",
    "    \"Precision\": [mod_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Failed to converge on scaled continuous and count features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets[\"transformed_scaled_lgst\"] = sig_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformation Method</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sig. features</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>None</td>\n",
       "      <td>0.777698</td>\n",
       "      <td>1258.385895</td>\n",
       "      <td>0.433649</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>17</td>\n",
       "      <td>Failed to converge on unscaled/transformed var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lgst</td>\n",
       "      <td>Scale all</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2037.900739</td>\n",
       "      <td>-0.019709</td>\n",
       "      <td>0.673511</td>\n",
       "      <td>0</td>\n",
       "      <td>Failed to converge on scaled continuous and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>Scale all</td>\n",
       "      <td>0.777698</td>\n",
       "      <td>1258.385895</td>\n",
       "      <td>0.433649</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>18</td>\n",
       "      <td>Failed to converge scaled continuous and count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>Scale all</td>\n",
       "      <td>0.763499</td>\n",
       "      <td>1112.265788</td>\n",
       "      <td>0.486691</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0</td>\n",
       "      <td>Failed to converge scaled continuous and count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>Transform continuous, scale count and discrete</td>\n",
       "      <td>0.781322</td>\n",
       "      <td>1233.197962</td>\n",
       "      <td>0.443342</td>\n",
       "      <td>0.871711</td>\n",
       "      <td>15</td>\n",
       "      <td>Failed to converge on transformed continuous, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>Transform continuous, scale count and discrete</td>\n",
       "      <td>0.774553</td>\n",
       "      <td>1103.942835</td>\n",
       "      <td>0.491244</td>\n",
       "      <td>0.856698</td>\n",
       "      <td>0</td>\n",
       "      <td>Failed to converge on scaled continuous and co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model                           Transformation Method       AUC  \\\n",
       "0  LinReg                                            None  0.777698   \n",
       "0    Lgst                                       Scale all  0.500000   \n",
       "0  LinReg                                       Scale all  0.777698   \n",
       "0   Logit                                       Scale all  0.763499   \n",
       "0  LinReg  Transform continuous, scale count and discrete  0.781322   \n",
       "0   Logit  Transform continuous, scale count and discrete  0.774553   \n",
       "\n",
       "           AIC        R2  Precision Sig. features  \\\n",
       "0  1258.385895  0.433649   0.859375            17   \n",
       "0  2037.900739 -0.019709   0.673511             0   \n",
       "0  1258.385895  0.433649   0.859375            18   \n",
       "0  1112.265788  0.486691   0.846626             0   \n",
       "0  1233.197962  0.443342   0.871711            15   \n",
       "0  1103.942835  0.491244   0.856698             0   \n",
       "\n",
       "                                               Notes  \n",
       "0  Failed to converge on unscaled/transformed var...  \n",
       "0  Failed to converge on scaled continuous and co...  \n",
       "0  Failed to converge scaled continuous and count...  \n",
       "0  Failed to converge scaled continuous and count...  \n",
       "0  Failed to converge on transformed continuous, ...  \n",
       "0  Failed to converge on scaled continuous and co...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save results\n",
    "file = \"A2 - Optimization Performance Report.csv\"\n",
    "modeling_results.export_csv(file)\n",
    "\n",
    "# Observe all performance\n",
    "modeling_results.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_squared</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [r_squared, vif]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vim_multicollinearity(df_transformed_cont_scaled_count_disc.loc[:, sig_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>HWT_SUBSCRIBER</td>  <th>  R-squared:         </th> <td>   0.443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.408</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.71</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 15 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>1.62e-121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:35:15</td>     <th>  Log-Likelihood:    </th> <td> -529.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1459</td>      <th>  AIC:               </th> <td>   1233.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1372</td>      <th>  BIC:               </th> <td>   1693.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    86</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                        <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE</th>                                      <td>   -0.0723</td> <td>    0.041</td> <td>   -1.754</td> <td> 0.080</td> <td>   -0.153</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_MEALS_ORDERED</th>                          <td>   -0.2163</td> <td>    0.188</td> <td>   -1.152</td> <td> 0.250</td> <td>   -0.585</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNIQUE_MEALS_PURCH</th>                           <td>    0.1908</td> <td>    0.115</td> <td>    1.660</td> <td> 0.097</td> <td>   -0.035</td> <td>    0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CUSTOMER_SERVICE_TICKETS_CNT</th>                 <td>    0.1752</td> <td>    0.092</td> <td>    1.906</td> <td> 0.057</td> <td>   -0.005</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRODUCT_CATEGORIES_VIEWED</th>                    <td>    0.0172</td> <td>    0.029</td> <td>    0.593</td> <td> 0.553</td> <td>   -0.040</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SITE_VISIT_TIME_PER_VISIT_AVG</th>                <td>    0.0417</td> <td>    0.044</td> <td>    0.945</td> <td> 0.345</td> <td>   -0.045</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_REGISTRATION</th>                          <td>    0.1165</td> <td>    0.030</td> <td>    3.941</td> <td> 0.000</td> <td>    0.059</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEALS_CANCEL_BEFORE_NOON</th>                     <td>    0.4318</td> <td>    0.091</td> <td>    4.744</td> <td> 0.000</td> <td>    0.253</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEALS_CANCEL_AFTER_NOON</th>                      <td>   -0.1359</td> <td>    0.066</td> <td>   -2.059</td> <td> 0.040</td> <td>   -0.265</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPECIFIED_TASTE_AND_PREFERENCES</th>              <td>    0.0759</td> <td>    0.021</td> <td>    3.577</td> <td> 0.000</td> <td>    0.034</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS_CNT</th>                                <td>    0.0916</td> <td>    0.050</td> <td>    1.834</td> <td> 0.067</td> <td>   -0.006</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS_CNT</th>                            <td>   -0.0388</td> <td>    0.018</td> <td>   -2.102</td> <td> 0.036</td> <td>   -0.075</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT</th>          <td>   -0.0694</td> <td>    0.141</td> <td>   -0.493</td> <td> 0.622</td> <td>   -0.346</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ORDERS_DELIVERED_BEFORE_DELIVERY_CNT</th>         <td>    0.0109</td> <td>    0.046</td> <td>    0.236</td> <td> 0.813</td> <td>   -0.080</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ORDERS_DELIVERED_AFTER_DELIVERY_CNT</th>          <td>   -0.0504</td> <td>    0.088</td> <td>   -0.571</td> <td> 0.568</td> <td>   -0.224</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PACKAGE_ROOM_AT_CUSTOMER</th>                     <td>    0.0114</td> <td>    0.023</td> <td>    0.496</td> <td> 0.620</td> <td>   -0.034</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FRIDGE_LOCKER_IN_PACKAGE_ROOM</th>                <td>    0.0165</td> <td>    0.017</td> <td>    0.945</td> <td> 0.345</td> <td>   -0.018</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE</th>         <td>   -0.0683</td> <td>    0.012</td> <td>   -5.628</td> <td> 0.000</td> <td>   -0.092</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SECONDS_WATCHING_PREP_VID_AVG</th>                <td>    0.0554</td> <td>    0.067</td> <td>    0.823</td> <td> 0.411</td> <td>   -0.077</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LARGEST_ORDER_SIZE</th>                           <td>   -0.1017</td> <td>    0.131</td> <td>   -0.776</td> <td> 0.438</td> <td>   -0.359</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED_CNT</th>                  <td>    0.0123</td> <td>    0.055</td> <td>    0.226</td> <td> 0.821</td> <td>   -0.095</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEAL_RATING_MEDIAN</th>                           <td>   -0.1063</td> <td>    0.116</td> <td>   -0.920</td> <td> 0.358</td> <td>   -0.333</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SITE_CLICKS_PER_VISIT_AVG</th>                    <td>   -0.1614</td> <td>    0.120</td> <td>   -1.342</td> <td> 0.180</td> <td>   -0.397</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PHOTOS_VIEWED_COUNT</th>                          <td>    0.1096</td> <td>    0.148</td> <td>    0.742</td> <td> 0.458</td> <td>   -0.180</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>missing_FAMILY_NAME</th>                          <td>    0.0938</td> <td>    0.061</td> <td>    1.546</td> <td> 0.122</td> <td>   -0.025</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_MEAL_CHOICE_SPECIFICITY</th>                   <td>   -0.5576</td> <td>    0.263</td> <td>   -2.119</td> <td> 0.034</td> <td>   -1.074</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_SITE_CLICK_RATE</th>                           <td>    0.0610</td> <td>    0.209</td> <td>    0.293</td> <td> 0.770</td> <td>   -0.348</td> <td>    0.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_SUBSCRIPTIONS_SYNERGY</th>                     <td>   -0.1171</td> <td>    0.053</td> <td>   -2.208</td> <td> 0.027</td> <td>   -0.221</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_ONLY_HWT_CUSTOMER</th>                         <td>    0.0153</td> <td>    0.030</td> <td>    0.503</td> <td> 0.615</td> <td>   -0.044</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_WP_INACTIVE_SUB</th>                           <td>    0.4401</td> <td>    0.227</td> <td>    1.941</td> <td> 0.053</td> <td>   -0.005</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_WP_BASIC_SUB</th>                              <td>    0.4107</td> <td>    0.226</td> <td>    1.816</td> <td> 0.070</td> <td>   -0.033</td> <td>    0.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_WP_PREMIUM_SUB</th>                            <td>    0.4872</td> <td>    0.226</td> <td>    2.151</td> <td> 0.032</td> <td>    0.043</td> <td>    0.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_REVENUE_hi</th>                               <td> 6.563e-05</td> <td>    0.054</td> <td>    0.001</td> <td> 0.999</td> <td>   -0.106</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_TOTAL_MEALS_ORDERED_hi</th>                   <td>   -0.0339</td> <td>    0.066</td> <td>   -0.515</td> <td> 0.606</td> <td>   -0.163</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_UNIQUE_MEALS_PURCH_hi</th>                    <td>   -0.1231</td> <td>    0.226</td> <td>   -0.544</td> <td> 0.587</td> <td>   -0.567</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_CUSTOMER_SERVICE_TICKETS_CNT_hi</th>          <td>   -0.4587</td> <td>    0.267</td> <td>   -1.715</td> <td> 0.087</td> <td>   -0.983</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_MEALS_CANCEL_BEFORE_NOON_hi</th>              <td>   -0.0609</td> <td>    0.117</td> <td>   -0.520</td> <td> 0.603</td> <td>   -0.291</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT_hi</th>   <td>   -0.0344</td> <td>    0.067</td> <td>   -0.513</td> <td> 0.608</td> <td>   -0.166</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_ORDERS_DELIVERED_BEFORE_DELIVERY_CNT_hi</th>  <td>    0.0074</td> <td>    0.065</td> <td>    0.114</td> <td> 0.909</td> <td>   -0.120</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_ORDERS_DELIVERED_AFTER_DELIVERY_CNT_hi</th>   <td>    0.0616</td> <td>    0.059</td> <td>    1.037</td> <td> 0.300</td> <td>   -0.055</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trend_FRIDGE_LOCKER_IN_PACKAGE_ROOM</th>          <td>    0.0165</td> <td>    0.017</td> <td>    0.945</td> <td> 0.345</td> <td>   -0.018</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flag_PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE_hi</th> <td>    0.6004</td> <td>    0.029</td> <td>   20.720</td> <td> 0.000</td> <td>    0.544</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_SECONDS_WATCHING_PREP_VID_AVG_hi</th>         <td>    0.1503</td> <td>    0.091</td> <td>    1.655</td> <td> 0.098</td> <td>   -0.028</td> <td>    0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_LARGEST_ORDER_SIZE_hi</th>                    <td>   -0.0044</td> <td>    0.090</td> <td>   -0.049</td> <td> 0.961</td> <td>   -0.180</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_MASTER_CLASSES_ATTENDED_CNT_hi</th>           <td>   -0.3865</td> <td>    0.169</td> <td>   -2.291</td> <td> 0.022</td> <td>   -0.717</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_MEAL_RATING_MEDIAN_hi</th>                    <td>    0.1497</td> <td>    0.168</td> <td>    0.892</td> <td> 0.373</td> <td>   -0.179</td> <td>    0.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_SITE_CLICKS_PER_VISIT_AVG_lo</th>             <td>   -0.2322</td> <td>    0.245</td> <td>   -0.947</td> <td> 0.344</td> <td>   -0.713</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_PHOTOS_VIEWED_COUNT_hi</th>                   <td>   -0.0315</td> <td>    0.060</td> <td>   -0.526</td> <td> 0.599</td> <td>   -0.149</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_fe_MEAL_CHOICE_SPECIFICITY_hi</th>            <td>    0.0353</td> <td>    0.078</td> <td>    0.449</td> <td> 0.653</td> <td>   -0.119</td> <td>    0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_fe_SITE_CLICK_RATE_hi</th>                    <td>   -0.0667</td> <td>    0.069</td> <td>   -0.971</td> <td> 0.332</td> <td>   -0.201</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_aol</th>                      <td>   -0.0469</td> <td>    0.055</td> <td>   -0.853</td> <td> 0.394</td> <td>   -0.155</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_apple</th>                    <td>   -0.1222</td> <td>    0.111</td> <td>   -1.100</td> <td> 0.272</td> <td>   -0.340</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_boeing</th>                   <td>   -0.0234</td> <td>    0.118</td> <td>   -0.198</td> <td> 0.843</td> <td>   -0.255</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_caterpillar</th>              <td>    0.0395</td> <td>    0.118</td> <td>    0.336</td> <td> 0.737</td> <td>   -0.192</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_chevron</th>                  <td>   -0.0348</td> <td>    0.111</td> <td>   -0.314</td> <td> 0.753</td> <td>   -0.252</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_cisco</th>                    <td>   -0.0126</td> <td>    0.128</td> <td>   -0.099</td> <td> 0.922</td> <td>   -0.263</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_cocacola</th>                 <td>   -0.0472</td> <td>    0.112</td> <td>   -0.423</td> <td> 0.672</td> <td>   -0.266</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_disney</th>                   <td>   -0.0416</td> <td>    0.120</td> <td>   -0.348</td> <td> 0.728</td> <td>   -0.276</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_dupont</th>                   <td>   -0.0821</td> <td>    0.116</td> <td>   -0.710</td> <td> 0.478</td> <td>   -0.309</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_exxon</th>                    <td>   -0.1766</td> <td>    0.118</td> <td>   -1.501</td> <td> 0.134</td> <td>   -0.407</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_ge</th>                       <td>    0.4232</td> <td>    0.199</td> <td>    2.128</td> <td> 0.033</td> <td>    0.033</td> <td>    0.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_gmail</th>                    <td>    0.0900</td> <td>    0.051</td> <td>    1.767</td> <td> 0.077</td> <td>   -0.010</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_goldmansacs</th>              <td>    0.0652</td> <td>    0.128</td> <td>    0.511</td> <td> 0.609</td> <td>   -0.185</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_homedepot</th>                <td>   -0.2386</td> <td>    0.129</td> <td>   -1.850</td> <td> 0.064</td> <td>   -0.492</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_hotmail</th>                  <td>   -0.0292</td> <td>    0.057</td> <td>   -0.513</td> <td> 0.608</td> <td>   -0.141</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_ibm</th>                      <td>   -0.1207</td> <td>    0.110</td> <td>   -1.097</td> <td> 0.273</td> <td>   -0.337</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_intel</th>                    <td>    0.1289</td> <td>    0.139</td> <td>    0.931</td> <td> 0.352</td> <td>   -0.143</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_jnj</th>                      <td>   -0.1196</td> <td>    0.112</td> <td>   -1.069</td> <td> 0.285</td> <td>   -0.339</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_jpmorgan</th>                 <td>    0.0368</td> <td>    0.123</td> <td>    0.301</td> <td> 0.764</td> <td>   -0.204</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_live</th>                     <td>    0.0100</td> <td>    0.057</td> <td>    0.177</td> <td> 0.860</td> <td>   -0.101</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_mcdonalds</th>                <td>   -0.1336</td> <td>    0.110</td> <td>   -1.219</td> <td> 0.223</td> <td>   -0.349</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_me</th>                       <td>    0.0993</td> <td>    0.056</td> <td>    1.765</td> <td> 0.078</td> <td>   -0.011</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_merck</th>                    <td>    0.0493</td> <td>    0.111</td> <td>    0.446</td> <td> 0.656</td> <td>   -0.168</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_microsoft</th>                <td>    0.0968</td> <td>    0.114</td> <td>    0.848</td> <td> 0.397</td> <td>   -0.127</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_mmm</th>                      <td>    0.1860</td> <td>    0.115</td> <td>    1.616</td> <td> 0.106</td> <td>   -0.040</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_msn</th>                      <td>    0.0335</td> <td>    0.053</td> <td>    0.639</td> <td> 0.523</td> <td>   -0.069</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_nike</th>                     <td>   -0.1112</td> <td>    0.121</td> <td>   -0.923</td> <td> 0.356</td> <td>   -0.348</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_passport</th>                 <td>    0.1063</td> <td>    0.055</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.002</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_pfizer</th>                   <td>    0.0502</td> <td>    0.124</td> <td>    0.405</td> <td> 0.685</td> <td>   -0.193</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_pg</th>                       <td>    0.1631</td> <td>    0.116</td> <td>    1.405</td> <td> 0.160</td> <td>   -0.065</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_protonmail</th>               <td>    0.1170</td> <td>    0.051</td> <td>    2.315</td> <td> 0.021</td> <td>    0.018</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_travelers</th>                <td>   -0.2299</td> <td>    0.117</td> <td>   -1.973</td> <td> 0.049</td> <td>   -0.459</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_unitedhealth</th>             <td>   -0.0015</td> <td>    0.113</td> <td>   -0.013</td> <td> 0.990</td> <td>   -0.223</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_unitedtech</th>               <td>    0.0699</td> <td>    0.128</td> <td>    0.546</td> <td> 0.585</td> <td>   -0.181</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_verizon</th>                  <td>    0.0133</td> <td>    0.116</td> <td>    0.115</td> <td> 0.909</td> <td>   -0.214</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_visa</th>                     <td>   -0.0525</td> <td>    0.123</td> <td>   -0.425</td> <td> 0.671</td> <td>   -0.295</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_walmart</th>                  <td>   -0.0266</td> <td>    0.121</td> <td>   -0.220</td> <td> 0.826</td> <td>   -0.264</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_COMPANY_yahoo</th>                    <td>    0.0695</td> <td>    0.052</td> <td>    1.331</td> <td> 0.183</td> <td>   -0.033</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_DOMAIN_junk_domain</th>               <td>    0.1730</td> <td>    0.162</td> <td>    1.071</td> <td> 0.285</td> <td>   -0.144</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_DOMAIN_personal_domain</th>           <td>    0.2765</td> <td>    0.141</td> <td>    1.960</td> <td> 0.050</td> <td>   -0.000</td> <td>    0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fe_CUSTOMER_DOMAIN_professional_domain</th>       <td>    0.4654</td> <td>    0.199</td> <td>    2.343</td> <td> 0.019</td> <td>    0.076</td> <td>    0.855</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>100.538</td> <th>  Durbin-Watson:     </th> <td>   1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  39.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.141</td>  <th>  Prob(JB):          </th> <td>3.05e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.248</td>  <th>  Cond. No.          </th> <td>9.51e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.91e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         HWT_SUBSCRIBER   R-squared:                       0.443\n",
       "Model:                            OLS   Adj. R-squared:                  0.408\n",
       "Method:                 Least Squares   F-statistic:                     12.71\n",
       "Date:                Sun, 15 Mar 2020   Prob (F-statistic):          1.62e-121\n",
       "Time:                        23:35:15   Log-Likelihood:                -529.60\n",
       "No. Observations:                1459   AIC:                             1233.\n",
       "Df Residuals:                    1372   BIC:                             1693.\n",
       "Df Model:                          86                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================================================\n",
       "                                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------------\n",
       "REVENUE                                         -0.0723      0.041     -1.754      0.080      -0.153       0.009\n",
       "TOTAL_MEALS_ORDERED                             -0.2163      0.188     -1.152      0.250      -0.585       0.152\n",
       "UNIQUE_MEALS_PURCH                               0.1908      0.115      1.660      0.097      -0.035       0.416\n",
       "CUSTOMER_SERVICE_TICKETS_CNT                     0.1752      0.092      1.906      0.057      -0.005       0.356\n",
       "PRODUCT_CATEGORIES_VIEWED                        0.0172      0.029      0.593      0.553      -0.040       0.074\n",
       "SITE_VISIT_TIME_PER_VISIT_AVG                    0.0417      0.044      0.945      0.345      -0.045       0.128\n",
       "MOBILE_REGISTRATION                              0.1165      0.030      3.941      0.000       0.059       0.175\n",
       "MEALS_CANCEL_BEFORE_NOON                         0.4318      0.091      4.744      0.000       0.253       0.610\n",
       "MEALS_CANCEL_AFTER_NOON                         -0.1359      0.066     -2.059      0.040      -0.265      -0.006\n",
       "SPECIFIED_TASTE_AND_PREFERENCES                  0.0759      0.021      3.577      0.000       0.034       0.118\n",
       "PC_LOGINS_CNT                                    0.0916      0.050      1.834      0.067      -0.006       0.190\n",
       "MOBILE_LOGINS_CNT                               -0.0388      0.018     -2.102      0.036      -0.075      -0.003\n",
       "WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT             -0.0694      0.141     -0.493      0.622      -0.346       0.207\n",
       "ORDERS_DELIVERED_BEFORE_DELIVERY_CNT             0.0109      0.046      0.236      0.813      -0.080       0.102\n",
       "ORDERS_DELIVERED_AFTER_DELIVERY_CNT             -0.0504      0.088     -0.571      0.568      -0.224       0.123\n",
       "PACKAGE_ROOM_AT_CUSTOMER                         0.0114      0.023      0.496      0.620      -0.034       0.057\n",
       "FRIDGE_LOCKER_IN_PACKAGE_ROOM                    0.0165      0.017      0.945      0.345      -0.018       0.051\n",
       "PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE            -0.0683      0.012     -5.628      0.000      -0.092      -0.044\n",
       "SECONDS_WATCHING_PREP_VID_AVG                    0.0554      0.067      0.823      0.411      -0.077       0.187\n",
       "LARGEST_ORDER_SIZE                              -0.1017      0.131     -0.776      0.438      -0.359       0.155\n",
       "MASTER_CLASSES_ATTENDED_CNT                      0.0123      0.055      0.226      0.821      -0.095       0.119\n",
       "MEAL_RATING_MEDIAN                              -0.1063      0.116     -0.920      0.358      -0.333       0.120\n",
       "SITE_CLICKS_PER_VISIT_AVG                       -0.1614      0.120     -1.342      0.180      -0.397       0.075\n",
       "PHOTOS_VIEWED_COUNT                              0.1096      0.148      0.742      0.458      -0.180       0.399\n",
       "missing_FAMILY_NAME                              0.0938      0.061      1.546      0.122      -0.025       0.213\n",
       "fe_MEAL_CHOICE_SPECIFICITY                      -0.5576      0.263     -2.119      0.034      -1.074      -0.041\n",
       "fe_SITE_CLICK_RATE                               0.0610      0.209      0.293      0.770      -0.348       0.470\n",
       "fe_SUBSCRIPTIONS_SYNERGY                        -0.1171      0.053     -2.208      0.027      -0.221      -0.013\n",
       "fe_ONLY_HWT_CUSTOMER                             0.0153      0.030      0.503      0.615      -0.044       0.075\n",
       "fe_WP_INACTIVE_SUB                               0.4401      0.227      1.941      0.053      -0.005       0.885\n",
       "fe_WP_BASIC_SUB                                  0.4107      0.226      1.816      0.070      -0.033       0.854\n",
       "fe_WP_PREMIUM_SUB                                0.4872      0.226      2.151      0.032       0.043       0.931\n",
       "out_REVENUE_hi                                6.563e-05      0.054      0.001      0.999      -0.106       0.106\n",
       "out_TOTAL_MEALS_ORDERED_hi                      -0.0339      0.066     -0.515      0.606      -0.163       0.095\n",
       "out_UNIQUE_MEALS_PURCH_hi                       -0.1231      0.226     -0.544      0.587      -0.567       0.321\n",
       "out_CUSTOMER_SERVICE_TICKETS_CNT_hi             -0.4587      0.267     -1.715      0.087      -0.983       0.066\n",
       "out_MEALS_CANCEL_BEFORE_NOON_hi                 -0.0609      0.117     -0.520      0.603      -0.291       0.169\n",
       "out_WEEKS_SUBSCRIBED_TO_WEEKLY_PLAN_CNT_hi      -0.0344      0.067     -0.513      0.608      -0.166       0.097\n",
       "out_ORDERS_DELIVERED_BEFORE_DELIVERY_CNT_hi      0.0074      0.065      0.114      0.909      -0.120       0.134\n",
       "out_ORDERS_DELIVERED_AFTER_DELIVERY_CNT_hi       0.0616      0.059      1.037      0.300      -0.055       0.178\n",
       "trend_FRIDGE_LOCKER_IN_PACKAGE_ROOM              0.0165      0.017      0.945      0.345      -0.018       0.051\n",
       "flag_PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE_hi     0.6004      0.029     20.720      0.000       0.544       0.657\n",
       "out_SECONDS_WATCHING_PREP_VID_AVG_hi             0.1503      0.091      1.655      0.098      -0.028       0.328\n",
       "out_LARGEST_ORDER_SIZE_hi                       -0.0044      0.090     -0.049      0.961      -0.180       0.171\n",
       "out_MASTER_CLASSES_ATTENDED_CNT_hi              -0.3865      0.169     -2.291      0.022      -0.717      -0.056\n",
       "out_MEAL_RATING_MEDIAN_hi                        0.1497      0.168      0.892      0.373      -0.179       0.479\n",
       "out_SITE_CLICKS_PER_VISIT_AVG_lo                -0.2322      0.245     -0.947      0.344      -0.713       0.249\n",
       "out_PHOTOS_VIEWED_COUNT_hi                      -0.0315      0.060     -0.526      0.599      -0.149       0.086\n",
       "out_fe_MEAL_CHOICE_SPECIFICITY_hi                0.0353      0.078      0.449      0.653      -0.119       0.189\n",
       "out_fe_SITE_CLICK_RATE_hi                       -0.0667      0.069     -0.971      0.332      -0.201       0.068\n",
       "fe_CUSTOMER_COMPANY_aol                         -0.0469      0.055     -0.853      0.394      -0.155       0.061\n",
       "fe_CUSTOMER_COMPANY_apple                       -0.1222      0.111     -1.100      0.272      -0.340       0.096\n",
       "fe_CUSTOMER_COMPANY_boeing                      -0.0234      0.118     -0.198      0.843      -0.255       0.208\n",
       "fe_CUSTOMER_COMPANY_caterpillar                  0.0395      0.118      0.336      0.737      -0.192       0.271\n",
       "fe_CUSTOMER_COMPANY_chevron                     -0.0348      0.111     -0.314      0.753      -0.252       0.183\n",
       "fe_CUSTOMER_COMPANY_cisco                       -0.0126      0.128     -0.099      0.922      -0.263       0.238\n",
       "fe_CUSTOMER_COMPANY_cocacola                    -0.0472      0.112     -0.423      0.672      -0.266       0.172\n",
       "fe_CUSTOMER_COMPANY_disney                      -0.0416      0.120     -0.348      0.728      -0.276       0.193\n",
       "fe_CUSTOMER_COMPANY_dupont                      -0.0821      0.116     -0.710      0.478      -0.309       0.145\n",
       "fe_CUSTOMER_COMPANY_exxon                       -0.1766      0.118     -1.501      0.134      -0.407       0.054\n",
       "fe_CUSTOMER_COMPANY_ge                           0.4232      0.199      2.128      0.033       0.033       0.813\n",
       "fe_CUSTOMER_COMPANY_gmail                        0.0900      0.051      1.767      0.077      -0.010       0.190\n",
       "fe_CUSTOMER_COMPANY_goldmansacs                  0.0652      0.128      0.511      0.609      -0.185       0.315\n",
       "fe_CUSTOMER_COMPANY_homedepot                   -0.2386      0.129     -1.850      0.064      -0.492       0.014\n",
       "fe_CUSTOMER_COMPANY_hotmail                     -0.0292      0.057     -0.513      0.608      -0.141       0.083\n",
       "fe_CUSTOMER_COMPANY_ibm                         -0.1207      0.110     -1.097      0.273      -0.337       0.095\n",
       "fe_CUSTOMER_COMPANY_intel                        0.1289      0.139      0.931      0.352      -0.143       0.401\n",
       "fe_CUSTOMER_COMPANY_jnj                         -0.1196      0.112     -1.069      0.285      -0.339       0.100\n",
       "fe_CUSTOMER_COMPANY_jpmorgan                     0.0368      0.123      0.301      0.764      -0.204       0.277\n",
       "fe_CUSTOMER_COMPANY_live                         0.0100      0.057      0.177      0.860      -0.101       0.121\n",
       "fe_CUSTOMER_COMPANY_mcdonalds                   -0.1336      0.110     -1.219      0.223      -0.349       0.081\n",
       "fe_CUSTOMER_COMPANY_me                           0.0993      0.056      1.765      0.078      -0.011       0.210\n",
       "fe_CUSTOMER_COMPANY_merck                        0.0493      0.111      0.446      0.656      -0.168       0.266\n",
       "fe_CUSTOMER_COMPANY_microsoft                    0.0968      0.114      0.848      0.397      -0.127       0.321\n",
       "fe_CUSTOMER_COMPANY_mmm                          0.1860      0.115      1.616      0.106      -0.040       0.412\n",
       "fe_CUSTOMER_COMPANY_msn                          0.0335      0.053      0.639      0.523      -0.069       0.137\n",
       "fe_CUSTOMER_COMPANY_nike                        -0.1112      0.121     -0.923      0.356      -0.348       0.125\n",
       "fe_CUSTOMER_COMPANY_passport                     0.1063      0.055      1.926      0.054      -0.002       0.215\n",
       "fe_CUSTOMER_COMPANY_pfizer                       0.0502      0.124      0.405      0.685      -0.193       0.293\n",
       "fe_CUSTOMER_COMPANY_pg                           0.1631      0.116      1.405      0.160      -0.065       0.391\n",
       "fe_CUSTOMER_COMPANY_protonmail                   0.1170      0.051      2.315      0.021       0.018       0.216\n",
       "fe_CUSTOMER_COMPANY_travelers                   -0.2299      0.117     -1.973      0.049      -0.459      -0.001\n",
       "fe_CUSTOMER_COMPANY_unitedhealth                -0.0015      0.113     -0.013      0.990      -0.223       0.220\n",
       "fe_CUSTOMER_COMPANY_unitedtech                   0.0699      0.128      0.546      0.585      -0.181       0.321\n",
       "fe_CUSTOMER_COMPANY_verizon                      0.0133      0.116      0.115      0.909      -0.214       0.241\n",
       "fe_CUSTOMER_COMPANY_visa                        -0.0525      0.123     -0.425      0.671      -0.295       0.190\n",
       "fe_CUSTOMER_COMPANY_walmart                     -0.0266      0.121     -0.220      0.826      -0.264       0.211\n",
       "fe_CUSTOMER_COMPANY_yahoo                        0.0695      0.052      1.331      0.183      -0.033       0.172\n",
       "fe_CUSTOMER_DOMAIN_junk_domain                   0.1730      0.162      1.071      0.285      -0.144       0.490\n",
       "fe_CUSTOMER_DOMAIN_personal_domain               0.2765      0.141      1.960      0.050      -0.000       0.553\n",
       "fe_CUSTOMER_DOMAIN_professional_domain           0.4654      0.199      2.343      0.019       0.076       0.855\n",
       "==============================================================================\n",
       "Omnibus:                      100.538   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.217\n",
       "Skew:                           0.141   Prob(JB):                     3.05e-09\n",
       "Kurtosis:                       2.248   Cond. No.                     9.51e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.91e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ols summary output for optimal linear regression\n",
    "lr_model_trans_scaled.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- The transformed and scaled linear regression produced the best overall performance in auc_score, AIC and rsquared abd were the only models to converge.\n",
    "- No multicollinearity, <em>Variance Inflation Factor > 9</em>, is observed between features not binary.\n",
    "\n",
    "Next Steps: Extract significant features from Linear and Logit Regression of and test for convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "\n",
    "Optimization strategy\n",
    "- Extract significant features\n",
    "    - Test on LR and logit\n",
    "- Selection criteria\n",
    "    - Overfitting - Cross validation train and test score\n",
    "    - AUC\n",
    "    - Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dataframe by significant features of last linear regression model\n",
    "df_transformed_cont_scaled_count_disc.to_csv(\"df_optimal.csv\")\n",
    "df_significant = df_transformed_cont_scaled_count_disc.copy()\n",
    "df_significant = df_significant.loc[:, [predictor] + sig_feature_sets['transformed_scaled_lr']]\n",
    "\n",
    "# df_significant.drop([\"fe_CUSTOMER_DOMAIN_professional_domain\"], axis=1, inplace=True)\n",
    "\n",
    "# setup ModelResults class\n",
    "modeling_optimal_results = ModelResults([\"Model\", \"Transformation Method\", \"AUC\", \"AIC\", \"R2\", \"Precision\", \"Sig. features\", \"Notes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on LR for Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_significant.loc[:, df_significant.columns.isin([predictor]) == False],\n",
    "            df_significant.loc[:, predictor],\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.360265\n",
      "         Iterations: 19\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 39\n",
      "         Hessian evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lr_model_optimal, lr_optimal_cm_score, lr_optimal_auc_score, lr_mod_optimal_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'ols', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save results\n",
    "modeling_optimal_results.save({\n",
    "    \"Model\": [\"LinReg\"],\n",
    "    \"Transformation Method\": [\"Transform continuous, scale count and discrete\"],\n",
    "    \"AUC\": [lr_optimal_auc_score],\n",
    "    \"AIC\": [lr_model_optimal.aic],\n",
    "    \"R2\": [lr_model_optimal.rsquared],\n",
    "    \"Precision\": [lr_mod_optimal_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Converged on all transformed and scaled features\"]\n",
    "})\n",
    "\n",
    "\n",
    "sig_feature_sets['pval_optimal_scale_train_lr'] = sig_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Logit for Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.360265\n",
      "         Iterations: 19\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 39\n",
      "         Hessian evaluations: 19\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "lgst_model_optimal, lgst_optimal_cm_score, lgst_optimal_auc_score, lgst_mod_optimal_precision, sig_features = statsmodel_ols_lgst('statsmodels', 'lgst', X_train, X_test, y_train, y_test, 0.5)\n",
    "\n",
    "# save results\n",
    "modeling_optimal_results.save({\n",
    "    \"Model\": [\"Logit\"],\n",
    "    \"Transformation Method\": [\"Transform continuous, scale count and discrete\"],\n",
    "    \"AUC\": [lgst_optimal_auc_score],\n",
    "    \"AIC\": [lgst_model_optimal.aic],\n",
    "    \"R2\": [lgst_model_optimal.prsquared],\n",
    "    \"Precision\": [lgst_mod_optimal_precision],\n",
    "    \"Sig. features\": [len(sig_features)],\n",
    "    \"Notes\": [\"Converged on all transformed and scaled features\"]\n",
    "})\n",
    "\n",
    "sig_feature_sets['pval_optimal_scale_train_lgst'] = sig_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Transformation Method</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>R2</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sig. features</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>Transform continuous, scale count and discrete</td>\n",
       "      <td>0.761217</td>\n",
       "      <td>1283.260446</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>10</td>\n",
       "      <td>Converged on all transformed and scaled features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>Transform continuous, scale count and discrete</td>\n",
       "      <td>0.765119</td>\n",
       "      <td>1081.253055</td>\n",
       "      <td>0.424877</td>\n",
       "      <td>0.848765</td>\n",
       "      <td>8</td>\n",
       "      <td>Converged on all transformed and scaled features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model                           Transformation Method       AUC  \\\n",
       "0  LinReg  Transform continuous, scale count and discrete  0.761217   \n",
       "0   Logit  Transform continuous, scale count and discrete  0.765119   \n",
       "\n",
       "           AIC        R2  Precision Sig. features  \\\n",
       "0  1283.260446  0.796912   0.860000            10   \n",
       "0  1081.253055  0.424877   0.848765             8   \n",
       "\n",
       "                                              Notes  \n",
       "0  Converged on all transformed and scaled features  \n",
       "0  Converged on all transformed and scaled features  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save results\n",
    "file = \"A2 - P-Value Optimization Performance Report.csv\"\n",
    "modeling_optimal_results.export_csv(file)\n",
    "\n",
    "# Observe all performance\n",
    "modeling_optimal_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes, both models converged on features and must be tested against classical assumptions of a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the 7 assumptions of a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The error term has a population mean of zero. Thus residuals do not bias predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Accept Null hypothesis', 'sample_mean': 0.01458782299596335}\n"
     ]
    }
   ],
   "source": [
    "lr_assumptions = NormalityTest(lr_model_optimal.resid, 0.05, X_train, 'HWT_SUBSCRIBER')\n",
    "print(lr_assumptions.check_population_mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. All independent variables are uncorrelated with error terms (accept for arr). Thus the error term cannot be explained by a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOBILE_REGISTRATION                            -0.105680\n",
       "MEALS_CANCEL_BEFORE_NOON                       -0.036222\n",
       "MEALS_CANCEL_AFTER_NOON                        -0.014871\n",
       "SPECIFIED_TASTE_AND_PREFERENCES                -0.060946\n",
       "MOBILE_LOGINS_CNT                              -0.110543\n",
       "PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE           -0.107511\n",
       "fe_MEAL_CHOICE_SPECIFICITY                     -0.035961\n",
       "fe_SUBSCRIPTIONS_SYNERGY                       -0.076382\n",
       "fe_WP_PREMIUM_SUB                              -0.014070\n",
       "flag_PRCNT_FOLLOWED_MEAL_RECOM_WEB_MOBILE_hi   -0.032633\n",
       "out_MASTER_CLASSES_ATTENDED_CNT_hi             -0.002303\n",
       "fe_CUSTOMER_COMPANY_ge                         -0.004745\n",
       "fe_CUSTOMER_COMPANY_protonmail                 -0.016012\n",
       "fe_CUSTOMER_COMPANY_travelers                  -0.004389\n",
       "fe_CUSTOMER_DOMAIN_professional_domain         -0.028743\n",
       "arr                                             1.000000\n",
       "Name: arr, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_assumptions.get_correlation_matrix().loc[:, \"arr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Error terms are uncorrelated with each other. An insignificant positive coeffecient means that the residuals do not have a relationship with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeffecient: x1    0.00002\n",
      "dtype: float64, p-value: 0.0772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1663754e9e8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "as_4 = sm.OLS(lr_model_optimal.resid, [i for i in range(0, len(lr_model_optimal.resid), 1)]).fit()\n",
    "print(\"Coeffecient: {}, p-value: {}\".format(as_4.params, round(as_4.pvalues[0], 4)))\n",
    "sns.scatterplot(\n",
    "    x = 'order',\n",
    "    y = 'arr',\n",
    "    data = pd.DataFrame({\"arr\": lr_model_optimal.resid, \"order\": [i for i in range(0, len(lr_model_optimal.resid), 1)]})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Residual terms obide by normality within the-1.5 and 2 standard deviations. Beyond these intervals, the residual show heteroscadistic behavior.\n",
    "    - The distribution soft-fails because it regressions are versatile enough to deal with this amount of behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qqplot_homo = lr_assumptions.check_homoscedasticity(lr_model_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. No Independent variable is a perfect linear function of other explanatory variables. Thus residuals do not show behaviours of multicollinearity.\n",
    "    - Variance Inflation Factor(VIF) for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_squared</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [r_squared, vif]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = lr_assumptions.get_vif()\n",
    "\n",
    "# multicollinear features\n",
    "vif[(vif.vif > 10) & (vif.vif < 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Optimization Effort\n",
    "1. The model is fit for use for both prediction and statistical feature inference and insights can be drawn from them.\n",
    "2. A final effort will be made to maximize the predictive power of this model for strategic marketing decisions.\n",
    "3. sklearn models considered,\n",
    "    - LinearRegression\n",
    "    - LogisticRegression\n",
    "4. AUC probability threshold for AUC & Precision optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dataframe by significant features of last linear regression model\n",
    "df_significant.to_csv(\"df_pre_final_model_selection.csv\")\n",
    "df_final_optimization = df_transformed_cont_scaled_count_disc.copy()\n",
    "df_final_optimization = df_final_optimization.loc[:, [predictor] + sig_feature_sets['pval_optimal_scale_train_lr']]\n",
    "\n",
    "# df_final_optimization.drop([\"fe_CUSTOMER_DOMAIN_professional_domain\"], axis=1, inplace=True)\n",
    "\n",
    "# setup ModelResults class\n",
    "final_optimal_results = ModelResults([\"Model\", \"Stability\", \"Test Score\", \"AUC\", \"AUC_thresh\", \"Precision\", \"Notes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data for cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_final_optimization.loc[:, df_final_optimization.columns.isin([predictor]) == False],\n",
    "            df_final_optimization.loc[:, predictor],\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on sklearn LinearRegression for Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364978\n",
      "         Iterations: 17\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 35\n",
      "         Hessian evaluations: 17\n"
     ]
    }
   ],
   "source": [
    "# load model and performance parameters\n",
    "best_precision = 0\n",
    "best_params = {}\n",
    "for i in [\"ols\", \"lgst\"]:\n",
    "    for thresh in np.arange(0.1, 1, 0.1):\n",
    "        lr_final, lr_optimal_cm_score, lr_optimal_auc_score, lr_mod_optimal_precision, sig_features = statsmodel_ols_lgst('sklearn', i, X_train, X_test, y_train, y_test, thresh);\n",
    "        train_score = lr_final.score(X_train, y_train)\n",
    "        test_score = lr_final.score(X_test, y_test)\n",
    "        \n",
    "        # get model that maximizes precision\n",
    "        if (lr_mod_optimal_precision > best_precision):\n",
    "            best_precision = lr_mod_optimal_precision\n",
    "            best_params = {\n",
    "                'model':i,\n",
    "                'cm': lr_optimal_cm_score,\n",
    "                'train_score': train_score,\n",
    "                'test': test_score,\n",
    "                'auc': lr_optimal_auc_score,\n",
    "                'auc_thresh': thresh,\n",
    "                'precision': lr_mod_optimal_precision,\n",
    "            }\n",
    "            \n",
    "        # save results\n",
    "        final_optimal_results.save({\n",
    "            \"Model\": [i],\n",
    "            \"Stability\": [(train_score-test_score)],\n",
    "            \"Test Score\": [test_score],\n",
    "            \"AUC\": [lr_optimal_auc_score],\n",
    "            \"AUC_thresh\": thresh,\n",
    "            \"Precision\": [lr_mod_optimal_precision],\n",
    "            \"Notes\": [\"Converged successfully\"]\n",
    "        })\n",
    "\n",
    "        sig_feature_sets['{}_{}'.format(i, thresh)] = X_train.columns;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was a linear model and with a class probability threshold of 0.8. This resulted in an AUC of 0.777 and a fully minimized Precision. This means that the model has a low probability of falsely classifying a customer as a HWT subscriber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'ols',\n",
       " 'cm': {'TN': 159, 'FP': 0, 'FN': 141, 'TP': 187},\n",
       " 'train_score': 0.3917382262670469,\n",
       " 'test': 0.3749864466001106,\n",
       " 'auc': 0.7850609756097561,\n",
       " 'auc_thresh': 0.8,\n",
       " 'precision': 1.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the linear model a class probability threshold of 0.6 and a precision of 0.938 achieved an AUC of 0.803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC_thresh</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.673511</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.515723</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.680498</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.548790</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.695745</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.701076</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.794092</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.803440</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.793440</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.963134</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ols</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.740854</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgst</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.862179</td>\n",
       "      <td>Converged successfully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Stability  Test Score       AUC  AUC_thresh  Precision  \\\n",
       "0   ols   0.016752    0.374986  0.500000         0.1   0.673511   \n",
       "0   ols   0.016752    0.374986  0.515723         0.2   0.680498   \n",
       "0   ols   0.016752    0.374986  0.548790         0.3   0.695745   \n",
       "0   ols   0.016752    0.374986  0.701076         0.4   0.786842   \n",
       "0   ols   0.016752    0.374986  0.794092         0.5   0.887755   \n",
       "0   ols   0.016752    0.374986  0.803440         0.6   0.938776   \n",
       "0   ols   0.016752    0.374986  0.793440         0.7   0.963134   \n",
       "0   ols   0.016752    0.374986  0.785061         0.8   1.000000   \n",
       "0   ols   0.016752    0.374986  0.740854         0.9   1.000000   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.1   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.2   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.3   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.4   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.5   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.6   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.7   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.8   0.862179   \n",
       "0  lgst   0.008623    0.790554  0.774841         0.9   0.862179   \n",
       "\n",
       "                    Notes  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  \n",
       "0  Converged successfully  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_optimal_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight 1\n",
    "The cross-selling strategy has introduced a new customer type; HWT only subscribers. They account for nearly 25% of existing customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HWT_SUBSCRIBER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe_WP_INACTIVE_SUB</th>\n",
       "      <th>fe_WP_BASIC_SUB</th>\n",
       "      <th>fe_WP_PREMIUM_SUB</th>\n",
       "      <th>fe_ONLY_HWT_CUSTOMER</th>\n",
       "      <th>MOBILE_REGISTRATION</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               HWT_SUBSCRIBER\n",
       "fe_WP_INACTIVE_SUB fe_WP_BASIC_SUB fe_WP_PREMIUM_SUB fe_ONLY_HWT_CUSTOMER MOBILE_REGISTRATION                \n",
       "0                  0               1                 0                    0                                20\n",
       "                                                                          1                               132\n",
       "                   1               0                 0                    0                                32\n",
       "                                                                          1                               248\n",
       "1                  0               0                 0                    0                                45\n",
       "                                                                          1                               519\n",
       "                                                     1                    0                                34\n",
       "                                                                          1                               291"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimization.loc[:, [\"fe_WP_BASIC_SUB\", \"fe_WP_PREMIUM_SUB\", \"fe_WP_INACTIVE_SUB\", \"fe_ONLY_HWT_CUSTOMER\", \"MOBILE_REGISTRATION\", \"HWT_SUBSCRIBER\"]].\\\n",
    "groupby([\"fe_WP_INACTIVE_SUB\", \"fe_WP_BASIC_SUB\", \"fe_WP_PREMIUM_SUB\", \"fe_ONLY_HWT_CUSTOMER\", \"MOBILE_REGISTRATION\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight 2\n",
    "HWT only subscribers see value in the product as their spend is nearly a third of dual subscription customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOBILE_LOGINS_CNT</th>\n",
       "      <th>PC_LOGINS_CNT</th>\n",
       "      <th>HWT_SUBSCRIBER</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe_ONLY_HWT_CUSTOMER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2180</td>\n",
       "      <td>8139</td>\n",
       "      <td>1478</td>\n",
       "      <td>3084106.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693</td>\n",
       "      <td>2595</td>\n",
       "      <td>468</td>\n",
       "      <td>1016684.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MOBILE_LOGINS_CNT  PC_LOGINS_CNT  HWT_SUBSCRIBER  \\\n",
       "fe_ONLY_HWT_CUSTOMER                                                     \n",
       "0                                  2180           8139            1478   \n",
       "1                                   693           2595             468   \n",
       "\n",
       "                         REVENUE  \n",
       "fe_ONLY_HWT_CUSTOMER              \n",
       "0                     3084106.75  \n",
       "1                     1016684.75  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimization\\\n",
    "    .loc[:, df_optimization.columns\\\n",
    "    .isin([\"fe_ONLY_HWT_CUSTOMER\", \"HWT_SUBSCRIBER\", \"MOBILE_LOGINS_CNT\", \"PC_LOGINS_CNT\", \"REVENUE\"]) == True]\\\n",
    "    .groupby(\"fe_ONLY_HWT_CUSTOMER\")\\\n",
    "    .agg({\"MOBILE_LOGINS_CNT\": 'sum', \"PC_LOGINS_CNT\": 'sum', \"HWT_SUBSCRIBER\": 'count', \"REVENUE\": 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drive cross-selling effectiveness, develop lists of recipes that can be paired with the wines you sell and optimize them for viewing on PC and Mobile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "362.685px",
    "left": "601.244px",
    "right": "20px",
    "top": "47.9829px",
    "width": "385.995px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
